{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tELL7IjRjP-"
      },
      "source": [
        "##### For connecting to google drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3rzbMz1RqEb",
        "outputId": "e5e27b63-1124-42ff-bde5-6b49a101a105"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### For running GSD section"
      ],
      "metadata": {
        "id": "IN65wmVpH6Ry"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqRoN1FLRxW6",
        "outputId": "95a15693-cd7f-42fa-b2cc-2a1ff01d35cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network CSV: /content/drive/MyDrive/Colab Notebooks/Temp data folder/\n",
            "Expression CSV: /content/drive/MyDrive/Colab Notebooks/paper3/inputs/Curated/\n"
          ]
        }
      ],
      "source": [
        "\n",
        "network_list = [\n",
        "    \"Normi.csv\",\n",
        "    \"SINCERITIES.csv\",\n",
        "    \"PPCOR.csv\",\n",
        "    \"GENIE3.csv\",\n",
        "    \"Bixgboost.csv\",\n",
        "    \"AGRN.csv\",\n",
        "    \"GreyNet.csv\",\n",
        "    \"LEAP.csv\",\n",
        "    \"SCNS.csv\",\n",
        "    \"SINGE.csv\",\n",
        "    \"GRNBOOST2.csv\",\n",
        "    \"SCODE.csv\",\n",
        "    \"Dyngenie3.csv\",\n",
        "    \"SCRIBE.csv\",\n",
        "    \"GRNVBEM.csv\",\n",
        "    \"GRISLI.csv\",\n",
        "    \"PIDC.csv\"\n",
        "]\n",
        "\n",
        "\n",
        "folder_list = [\"GSD/GSD-2000-1\"] #Using one dataset as a sample\n",
        "# folder_name = \"\" #GSD,HSC,VSC, mCAD\n",
        "expression_file_name =\"ExpressionData.csv\"\n",
        "\n",
        "network_csv_path = #NETWORK csv file from algorithms\n",
        "expression_csv_path =  #LOCATION of Expression files\n",
        "print(\"Network CSV:\", network_csv_path)\n",
        "print(\"Expression CSV:\", expression_csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "SWo7meWDg69o",
        "outputId": "fa283096-db87-4adb-bfdc-c53b8ce22ff2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Post_processing_paper_ideas//GSD/GSD-2000-1/refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_Normi_0.1_10.csv\n",
            "Saved: /content/drive/MyDrive/Post_processing_paper_ideas//GSD/GSD-2000-1/refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_Normi_0.1_10.csv\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3963713389.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0mnet_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_network_filtered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenes_present\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m                 refined_df = refine_network_v11_ecdf_symmetric(\n\u001b[0m\u001b[1;32m    142\u001b[0m                     \u001b[0mnet_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                     \u001b[0mexpr_df_z\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3963713389.py\u001b[0m in \u001b[0;36mrefine_network_v11_ecdf_symmetric\u001b[0;34m(net_df, expr_df_z, mi_n_neighbors, alpha, keep_top_percent)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \"\"\"\n\u001b[1;32m    108\u001b[0m     \u001b[0mw_norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_minmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"EdgeWeight\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_mi_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpr_df_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmi_n_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmi_n_neighbors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# normalized MI\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mcontext_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclr_v11_ecdf_symmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3963713389.py\u001b[0m in \u001b[0;36medge_mi_scores\u001b[0;34m(net_df, expr_df_z, mi_n_neighbors)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0myt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mmi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmutual_info_regression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmi_n_neighbors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mraw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36mmutual_info_regression\u001b[0;34m(X, y, discrete_features, n_neighbors, copy, random_state, n_jobs)\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.6\u001b[0m\u001b[0;34m...\u001b[0m  \u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \"\"\"\n\u001b[0;32m--> 441\u001b[0;31m     return _estimate_mi(\n\u001b[0m\u001b[1;32m    442\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_estimate_mi\u001b[0;34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state, n_jobs)\u001b[0m\n\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m     mi = Parallel(n_jobs=n_jobs)(\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_compute_mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_feature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iterate_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscrete_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1984\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1985\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1986\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1988\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1912\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1914\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1915\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi\u001b[0;34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_compute_mi_cc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/feature_selection/_mutual_info.py\u001b[0m in \u001b[0;36m_compute_mi_cc\u001b[0;34m(x, y, n_neighbors)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;34m+\u001b[0m \u001b[0mdigamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdigamma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mny\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     )\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# -------------------- I/O helpers -------------------- #\n",
        "\n",
        "def load_and_zscore_expression(expression_path: str) -> pd.DataFrame:\n",
        "    \"\"\"ExpressionData.csv: rows=genes, cols=cells -> zscore per gene.\"\"\"\n",
        "    expr_df = pd.read_csv(expression_path, index_col=0)\n",
        "    expr_df = expr_df.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "    X = expr_df.values.astype(np.float64)\n",
        "    mu = X.mean(axis=1, keepdims=True)\n",
        "    sd = X.std(axis=1, keepdims=True)\n",
        "    sd = np.where(sd < 1e-6, 1.0, sd)\n",
        "    Xz = (X - mu) / sd\n",
        "    return pd.DataFrame(Xz, index=expr_df.index)\n",
        "\n",
        "def load_network_filtered(network_path: str, genes_present: set[str]) -> pd.DataFrame:\n",
        "    \"\"\"Expected columns: Gene1, Gene2, EdgeWeight.\"\"\"\n",
        "    df = pd.read_csv(network_path)\n",
        "    df = df[df[\"Gene1\"].isin(genes_present) & df[\"Gene2\"].isin(genes_present)].copy()\n",
        "    df[\"EdgeWeight\"] = df[\"EdgeWeight\"].astype(float)\n",
        "    return df\n",
        "\n",
        "# -------------------- scoring utils -------------------- #\n",
        "\n",
        "def normalize_minmax(x, eps=1e-12):\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    if x.size == 0:\n",
        "        return x\n",
        "    return (x - x.min()) / (x.max() - x.min() + eps)\n",
        "\n",
        "def keep_top_percent_df(df: pd.DataFrame, score_col=\"EdgeWeight\", keep_top_percent=100.0) -> pd.DataFrame:\n",
        "    if len(df) == 0:\n",
        "        return df\n",
        "    scores = df[score_col].to_numpy(dtype=np.float64)\n",
        "    k = max(1, int(len(scores) * float(keep_top_percent) / 100.0))\n",
        "    thr = np.partition(scores, -k)[-k]\n",
        "    return df[df[score_col] >= thr].copy()\n",
        "\n",
        "def edge_mi_scores(net_df: pd.DataFrame, expr_df_z: pd.DataFrame, mi_n_neighbors=10):\n",
        "    \"\"\"MI(Gene1, Gene2) for each edge; returns (raw, minmax_norm).\"\"\"\n",
        "    genes = expr_df_z.index.to_list()\n",
        "    gene_to_row = {g: i for i, g in enumerate(genes)}\n",
        "    X = expr_df_z.values  # genes x cells\n",
        "\n",
        "    src = net_df[\"Gene1\"].map(gene_to_row).to_numpy()\n",
        "    dst = net_df[\"Gene2\"].map(gene_to_row).to_numpy()\n",
        "\n",
        "    raw = np.zeros(len(net_df), dtype=np.float64)\n",
        "    for i, (s, t) in enumerate(zip(src, dst)):\n",
        "        xs = X[s, :].reshape(-1, 1)\n",
        "        yt = X[t, :]\n",
        "        mi = mutual_info_regression(xs, yt, n_neighbors=mi_n_neighbors, random_state=0)[0]\n",
        "        raw[i] = 0.0 if np.isnan(mi) else float(mi)\n",
        "\n",
        "    return raw, normalize_minmax(raw)\n",
        "\n",
        "# -------------------- v11_ecdf_symmetric core -------------------- #\n",
        "\n",
        "def clr_v11_ecdf_symmetric(net_df: pd.DataFrame, base_values: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Implements v11_ecdf_symmetric:\n",
        "      - context = ecdf\n",
        "      - symmetry = undirected_symmetric\n",
        "      - combine = l2\n",
        "    \"\"\"\n",
        "    df = net_df[[\"Gene1\", \"Gene2\"]].copy()\n",
        "    df[\"_v\"] = np.asarray(base_values, dtype=np.float64)\n",
        "\n",
        "    # long-form to compute ECDF per incident gene\n",
        "    long = pd.concat(\n",
        "        [\n",
        "            df[[\"Gene1\", \"_v\"]].rename(columns={\"Gene1\": \"Gene\"}).assign(_side=\"A\", _idx=np.arange(len(df))),\n",
        "            df[[\"Gene2\", \"_v\"]].rename(columns={\"Gene2\": \"Gene\"}).assign(_side=\"B\", _idx=np.arange(len(df))),\n",
        "        ],\n",
        "        ignore_index=True,\n",
        "    )\n",
        "\n",
        "    long[\"_p\"] = long.groupby(\"Gene\")[\"_v\"].rank(pct=True, method=\"average\")\n",
        "    p_a = long[long[\"_side\"] == \"A\"].sort_values(\"_idx\")[\"_p\"].to_numpy(dtype=np.float64)\n",
        "    p_b = long[long[\"_side\"] == \"B\"].sort_values(\"_idx\")[\"_p\"].to_numpy(dtype=np.float64)\n",
        "\n",
        "    score = np.sqrt(p_a * p_a + p_b * p_b)  # l2 combine\n",
        "    return normalize_minmax(score)\n",
        "\n",
        "def blend_linear(a, b, alpha: float):\n",
        "    \"\"\"alpha*a + (1-alpha)*b, both assumed normalized [0,1].\"\"\"\n",
        "    return float(alpha) * a + (1.0 - float(alpha)) * b\n",
        "\n",
        "def refine_network_v11_ecdf_symmetric(\n",
        "    net_df: pd.DataFrame,\n",
        "    expr_df_z: pd.DataFrame,\n",
        "    *,\n",
        "    mi_n_neighbors=10,\n",
        "    alpha=0.8,\n",
        "    keep_top_percent=100.0,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Pipeline:\n",
        "      1) base signal = MI association (minmax normalized)\n",
        "      2) context score = v11_ecdf_symmetric on base\n",
        "      3) blend with original normalized EdgeWeight\n",
        "      4) keep top X%\n",
        "    \"\"\"\n",
        "    w_norm = normalize_minmax(net_df[\"EdgeWeight\"].to_numpy(dtype=np.float64))\n",
        "    _, base = edge_mi_scores(net_df, expr_df_z, mi_n_neighbors=mi_n_neighbors)  # normalized MI\n",
        "    context_score = clr_v11_ecdf_symmetric(net_df, base)\n",
        "\n",
        "    final = blend_linear(context_score, w_norm, alpha=alpha)\n",
        "\n",
        "    out = net_df[[\"Gene1\", \"Gene2\"]].copy()\n",
        "    out[\"EdgeWeight\"] = final\n",
        "    return keep_top_percent_df(out, \"EdgeWeight\", keep_top_percent)\n",
        "\n",
        "# -------------------- run on folders / networks -------------------- #\n",
        "\n",
        "# You already have these in your notebook/script:\n",
        "# folder_list, folder_name, expression_csv_path, network_csv_path, network_list\n",
        "\n",
        "keep_top_percent = 100.0\n",
        "\n",
        "alpha_list =[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9] #0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9\n",
        "neigh_list =[5,6,7,8,9,10,11,12,13,14,15] #5,6,7,8,9,10,11,12,13,14,15\n",
        "for alpha_val in alpha_list:\n",
        "    for neigh_val in neigh_list:\n",
        "        for l in folder_list:\n",
        "            output_csv_path = #Output Location\n",
        "            os.makedirs(output_csv_path, exist_ok=True)\n",
        "\n",
        "            expr_path = f\"{expression_csv_path}{l}/ExpressionData.csv\"\n",
        "            expr_df_z = load_and_zscore_expression(expr_path)\n",
        "            genes_present = set(expr_df_z.index)\n",
        "\n",
        "            for n in network_list:\n",
        "                net_path = f\"{network_csv_path}{l}/{n}\"\n",
        "                net_df = load_network_filtered(net_path, genes_present)\n",
        "\n",
        "                refined_df = refine_network_v11_ecdf_symmetric(\n",
        "                    net_df,\n",
        "                    expr_df_z,\n",
        "                    mi_n_neighbors=neigh_val,\n",
        "                    alpha=alpha_val,\n",
        "                    keep_top_percent=keep_top_percent,\n",
        "                )\n",
        "\n",
        "                base = n.replace(\".csv\", \"\")\n",
        "                out_file = os.path.join(output_csv_path, f\"refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_{base}_{alpha_val}_{neigh_val}.csv\")\n",
        "                print(out_file)\n",
        "                refined_df.to_csv(out_file, index=False)\n",
        "                print(\"Saved:\", out_file)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### For running HIV section"
      ],
      "metadata": {
        "id": "ClZqsAWuH--c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L4dBeW8kufwB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df775c06-3417-4724-9eda-59a82d4a4f05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Network CSV: /content/drive/MyDrive/Colab Notebooks/Paper_4_Preprocessing/HIV/\n",
            "Expression CSV: /content/drive/MyDrive/Colab Notebooks/Paper_4_Preprocessing/HIV/\n"
          ]
        }
      ],
      "source": [
        "\n",
        "network_list = [\n",
        "    \"1_AGRN_ETR.csv\",\n",
        "]\n",
        "\n",
        "\n",
        "folder_list = [\n",
        "    \"HL_L\"\n",
        "    # \"HVL_VL\",\n",
        "    # \"H_H\",\n",
        "    # \"N_H\",\n",
        "    # \"N_L\",\n",
        "    # \"N_VL\"\n",
        "] #Sample dataset with HIV-Leishmaniasis\n",
        "folder_name = \"\" #GSD,HSC,VSC, mCAD\n",
        "expression_file_name =\"ExpressionData.csv\"\n",
        "\n",
        "\n",
        "network_csv_path = #NETWORK csv file from algorithms run on HIV File\n",
        "expression_csv_path =   #LOCATION of Expression files\n",
        "\n",
        "print(\"Network CSV:\", network_csv_path)\n",
        "print(\"Expression CSV:\", expression_csv_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.feature_selection import mutual_info_regression\n",
        "\n",
        "# -------------------- I/O helpers -------------------- #\n",
        "\n",
        "def load_and_zscore_expression(expression_path: str) -> pd.DataFrame:\n",
        "    \"\"\"ExpressionData.csv: rows=genes, cols=cells -> zscore per gene.\"\"\"\n",
        "    expr_df = pd.read_csv(expression_path, index_col=0)\n",
        "    expr_df = expr_df.replace([np.inf, -np.inf], np.nan).fillna(0.0)\n",
        "\n",
        "    X = expr_df.values.astype(np.float64)\n",
        "    mu = X.mean(axis=1, keepdims=True)\n",
        "    sd = X.std(axis=1, keepdims=True)\n",
        "    sd = np.where(sd < 1e-6, 1.0, sd)\n",
        "    Xz = (X - mu) / sd\n",
        "    return pd.DataFrame(Xz, index=expr_df.index)\n",
        "\n",
        "def load_network_filtered(network_path: str, genes_present: set[str]) -> pd.DataFrame:\n",
        "    \"\"\"Expected columns: Gene1, Gene2, EdgeWeight.\"\"\"\n",
        "    df = pd.read_csv(network_path)\n",
        "    df = df[df[\"Gene1\"].isin(genes_present) & df[\"Gene2\"].isin(genes_present)].copy()\n",
        "    df[\"EdgeWeight\"] = df[\"EdgeWeight\"].astype(float)\n",
        "    return df\n",
        "\n",
        "# -------------------- scoring utils -------------------- #\n",
        "\n",
        "def normalize_minmax(x, eps=1e-12):\n",
        "    x = np.asarray(x, dtype=np.float64)\n",
        "    if x.size == 0:\n",
        "        return x\n",
        "    return (x - x.min()) / (x.max() - x.min() + eps)\n",
        "\n",
        "def keep_top_percent_df(df: pd.DataFrame, score_col=\"EdgeWeight\", keep_top_percent=100.0) -> pd.DataFrame:\n",
        "    if len(df) == 0:\n",
        "        return df\n",
        "    scores = df[score_col].to_numpy(dtype=np.float64)\n",
        "    k = max(1, int(len(scores) * float(keep_top_percent) / 100.0))\n",
        "    thr = np.partition(scores, -k)[-k]\n",
        "    return df[df[score_col] >= thr].copy()\n",
        "\n",
        "def edge_mi_scores(net_df: pd.DataFrame, expr_df_z: pd.DataFrame, mi_n_neighbors=10):\n",
        "    \"\"\"MI(Gene1, Gene2) for each edge; returns (raw, minmax_norm).\"\"\"\n",
        "    genes = expr_df_z.index.to_list()\n",
        "    gene_to_row = {g: i for i, g in enumerate(genes)}\n",
        "    X = expr_df_z.values  # genes x cells\n",
        "\n",
        "    src = net_df[\"Gene1\"].map(gene_to_row).to_numpy()\n",
        "    dst = net_df[\"Gene2\"].map(gene_to_row).to_numpy()\n",
        "\n",
        "    raw = np.zeros(len(net_df), dtype=np.float64)\n",
        "    for i, (s, t) in enumerate(zip(src, dst)):\n",
        "        xs = X[s, :].reshape(-1, 1)\n",
        "        yt = X[t, :]\n",
        "        mi = mutual_info_regression(xs, yt, n_neighbors=mi_n_neighbors, random_state=0)[0]\n",
        "        raw[i] = 0.0 if np.isnan(mi) else float(mi)\n",
        "\n",
        "    return raw, normalize_minmax(raw)\n",
        "\n",
        "# -------------------- v11_ecdf_symmetric core -------------------- #\n",
        "\n",
        "def clr_v11_ecdf_symmetric(net_df: pd.DataFrame, base_values: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    Implements v11_ecdf_symmetric:\n",
        "      - context = ecdf\n",
        "      - symmetry = undirected_symmetric\n",
        "      - combine = l2\n",
        "    \"\"\"\n",
        "    df = net_df[[\"Gene1\", \"Gene2\"]].copy()\n",
        "    df[\"_v\"] = np.asarray(base_values, dtype=np.float64)\n",
        "\n",
        "    # long-form to compute ECDF per incident gene\n",
        "    long = pd.concat(\n",
        "        [\n",
        "            df[[\"Gene1\", \"_v\"]].rename(columns={\"Gene1\": \"Gene\"}).assign(_side=\"A\", _idx=np.arange(len(df))),\n",
        "            df[[\"Gene2\", \"_v\"]].rename(columns={\"Gene2\": \"Gene\"}).assign(_side=\"B\", _idx=np.arange(len(df))),\n",
        "        ],\n",
        "        ignore_index=True,\n",
        "    )\n",
        "\n",
        "    long[\"_p\"] = long.groupby(\"Gene\")[\"_v\"].rank(pct=True, method=\"average\")\n",
        "    p_a = long[long[\"_side\"] == \"A\"].sort_values(\"_idx\")[\"_p\"].to_numpy(dtype=np.float64)\n",
        "    p_b = long[long[\"_side\"] == \"B\"].sort_values(\"_idx\")[\"_p\"].to_numpy(dtype=np.float64)\n",
        "\n",
        "    score = np.sqrt(p_a * p_a + p_b * p_b)  # l2 combine\n",
        "    return normalize_minmax(score)\n",
        "\n",
        "def blend_linear(a, b, alpha: float):\n",
        "    \"\"\"alpha*a + (1-alpha)*b, both assumed normalized [0,1].\"\"\"\n",
        "    return float(alpha) * a + (1.0 - float(alpha)) * b\n",
        "\n",
        "def refine_network_v11_ecdf_symmetric(\n",
        "    net_df: pd.DataFrame,\n",
        "    expr_df_z: pd.DataFrame,\n",
        "    *,\n",
        "    mi_n_neighbors=10,\n",
        "    alpha=0.8,\n",
        "    keep_top_percent=100.0,\n",
        ") -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Pipeline:\n",
        "      1) base signal = MI association (minmax normalized)\n",
        "      2) context score = v11_ecdf_symmetric on base\n",
        "      3) blend with original normalized EdgeWeight\n",
        "      4) keep top X%\n",
        "    \"\"\"\n",
        "    w_norm = normalize_minmax(net_df[\"EdgeWeight\"].to_numpy(dtype=np.float64))\n",
        "    _, base = edge_mi_scores(net_df, expr_df_z, mi_n_neighbors=mi_n_neighbors)  # normalized MI\n",
        "    context_score = clr_v11_ecdf_symmetric(net_df, base)\n",
        "\n",
        "    final = blend_linear(context_score, w_norm, alpha=alpha)\n",
        "\n",
        "    out = net_df[[\"Gene1\", \"Gene2\"]].copy()\n",
        "    out[\"EdgeWeight\"] = final\n",
        "    return keep_top_percent_df(out, \"EdgeWeight\", keep_top_percent)\n",
        "\n",
        "# -------------------- run on folders / networks -------------------- #\n",
        "\n",
        "# You already have these in your notebook/script:\n",
        "# folder_list, folder_name, expression_csv_path, network_csv_path, network_list\n",
        "\n",
        "keep_top_percent = 100.0\n",
        "\n",
        "alpha_list =[0.1] #0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9  0.6,0.7,0.8,0.9\n",
        "neigh_list =[11] #5,6,7,8,9,10,11,12,13,14,15 ,10,11,12,13,14,15\n",
        "for alpha_val in alpha_list:\n",
        "    for neigh_val in neigh_list:\n",
        "        for l in folder_list:\n",
        "            output_csv_path = #Output Location\n",
        "            os.makedirs(output_csv_path, exist_ok=True)\n",
        "\n",
        "            expr_path = f\"{expression_csv_path}{l}/ExpressionData.csv\"\n",
        "            expr_df_z = load_and_zscore_expression(expr_path)\n",
        "            genes_present = set(expr_df_z.index)\n",
        "\n",
        "            for n in network_list:\n",
        "                net_path = f\"{network_csv_path}{l}/{n}\"\n",
        "                net_df = load_network_filtered(net_path, genes_present)\n",
        "\n",
        "                refined_df = refine_network_v11_ecdf_symmetric(\n",
        "                    net_df,\n",
        "                    expr_df_z,\n",
        "                    mi_n_neighbors=neigh_val,\n",
        "                    alpha=alpha_val,\n",
        "                    keep_top_percent=keep_top_percent,\n",
        "                )\n",
        "\n",
        "                base = n.replace(\".csv\", \"\")\n",
        "                out_file = os.path.join(output_csv_path, f\"refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_{base}_{alpha_val}_{neigh_val}.csv\")\n",
        "                refined_df.to_csv(out_file, index=False)\n",
        "                print(\"Saved:\", out_file)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MugiIl3BIKik",
        "outputId": "c3270aa5-ccc5-4562-c2cf-fac09efb6da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: /content/drive/MyDrive/Colab Notebooks/Paper_4_Preprocessing/HIV//HL_L/refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_1_AGRN_ETR_0.1_11.csv\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/Paper_4_Preprocessing/HIV//HVL_VL/refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_1_AGRN_ETR_0.1_11.csv\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/Paper_4_Preprocessing/HIV//H_H/refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_1_AGRN_ETR_0.1_11.csv\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/Paper_4_Preprocessing/HIV//N_H/refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_1_AGRN_ETR_0.1_11.csv\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/Paper_4_Preprocessing/HIV//N_L/refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_1_AGRN_ETR_0.1_11.csv\n",
            "Saved: /content/drive/MyDrive/Colab Notebooks/Paper_4_Preprocessing/HIV//N_VL/refined_network_CLR_ASSOC__mi__v11_ecdf_symmetric_1_AGRN_ETR_0.1_11.csv\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}